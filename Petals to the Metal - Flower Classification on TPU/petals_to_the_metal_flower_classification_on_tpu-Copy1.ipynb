{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2022-10-16T16:25:12.466921Z",
     "iopub.status.busy": "2022-10-16T16:25:12.466546Z",
     "iopub.status.idle": "2022-10-16T16:25:12.476392Z",
     "shell.execute_reply": "2022-10-16T16:25:12.475316Z",
     "shell.execute_reply.started": "2022-10-16T16:25:12.466889Z"
    },
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.data.experimental import TFRecordWriter\n",
    "from sklearn.datasets import load_sample_image\n",
    "from IPython.display import Image\n",
    "from tensorflow.train import BytesList, FloatList, Int64List\n",
    "from tensorflow.train import Example, Features, Feature\n",
    "import tfrecord\n",
    "import cv2\n",
    "import glob\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "from torchvision.io import read_image\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import copy\n",
    "import torch.nn as nn\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "8200\n",
      "True\n",
      "<module 'torch.backends' from 'C:\\\\Users\\\\alex\\\\anaconda3\\\\lib\\\\site-packages\\\\torch\\\\backends\\\\__init__.py'>\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.backends.cudnn.version())\n",
    "print(torch.backends.cudnn.m.is_available())\n",
    "print(torch.backends)\n",
    "# print(torch.ones(5,5, device=\"opencl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[918, 199, 296,  ...,  10, 857, 163],\n",
      "        [447, 323,  54,  ..., 859, 492, 490],\n",
      "        [152, 391, 330,  ...,   3, 121, 345],\n",
      "        ...,\n",
      "        [  6, 579, 643,  ..., 284, 708, 610],\n",
      "        [655, 195, 357,  ..., 851,  63, 680],\n",
      "        [287, 605, 933,  ..., 220, 693, 940]])\n",
      "Device Name:  cpu\n"
     ]
    }
   ],
   "source": [
    "a = torch.randint(1, 1000, (10000 * 5, 10000))\n",
    "print(a)\n",
    "print(\"Device Name: \", a.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.5754,  9.9342, 10.0969,  ...,  8.7902, 10.5457,  9.8535],\n",
      "        [10.2686, 10.1330,  9.4180,  ..., 10.5467, 10.3090, 10.3073],\n",
      "        [ 9.8253, 10.2125, 10.1419,  ...,  8.3677,  9.7341, 10.1604],\n",
      "        ...,\n",
      "        [ 8.6084, 10.3779, 10.4225,  ..., 10.0798, 10.4636, 10.4000],\n",
      "        [10.4304,  9.9260, 10.1746,  ..., 10.5427,  9.4776, 10.4464],\n",
      "        [10.0842, 10.3965, 10.5824,  ...,  9.9751, 10.4545, 10.5857]])\n"
     ]
    }
   ],
   "source": [
    "aa = (((((a ** (1/22)) ** 3) ** 0.1) * 2) ** 3)\n",
    "print(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "CUDA Device ID:  0\n",
      "Name of the current CUDA Device:  NVIDIA GeForce RTX 3060\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)\n",
    "cuda_id = torch.cuda.current_device()\n",
    "print(\"CUDA Device ID: \", torch.cuda.current_device())\n",
    "print(\"Name of the current CUDA Device: \", torch.cuda.get_device_name(cuda_id))\n",
    "torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[930, 462, 807,  ..., 311, 246, 306],\n",
      "        [203, 825, 947,  ...,  94, 917,  58],\n",
      "        [ 30, 502, 682,  ...,  23, 689, 479],\n",
      "        ...,\n",
      "        [187, 764, 852,  ..., 388, 323, 218],\n",
      "        [186, 886, 425,  ..., 825,  21, 354],\n",
      "        [752, 144, 586,  ..., 838, 773, 538]], device='cuda:0')\n",
      "Device Name:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "# gc.collect()\n",
    "b = torch.randint(1, 1000, (10000 * 5, 10000))\n",
    "b = b.to(torch.device(\"cuda\"))\n",
    "print(b)\n",
    "print(\"Device Name: \", b.device)\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.5810, 10.2825, 10.5198,  ..., 10.1173, 10.0208, 10.1106],\n",
      "        [ 9.9423, 10.5293, 10.5889,  ...,  9.6341, 10.5749,  9.4456],\n",
      "        [ 9.1943, 10.3175, 10.4476,  ...,  9.0949, 10.4520, 10.2977],\n",
      "        ...,\n",
      "        [ 9.9090, 10.4963, 10.5432,  ..., 10.2093, 10.1330,  9.9714],\n",
      "        [ 9.9068, 10.5601, 10.2474,  ..., 10.5293,  9.0611, 10.1711],\n",
      "        [10.4895,  9.8036, 10.3830,  ..., 10.5360, 10.5013, 10.3467]],\n",
      "       device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "bb = (((((b ** (1/22)) ** 3) ** 0.1) * 2) ** 3)\n",
    "print(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.5754,  9.9342, 10.0969,  ...,  8.7902, 10.5457,  9.8535],\n",
      "        [10.2686, 10.1330,  9.4180,  ..., 10.5467, 10.3090, 10.3073],\n",
      "        [ 9.8253, 10.2125, 10.1419,  ...,  8.3677,  9.7341, 10.1604],\n",
      "        ...,\n",
      "        [ 8.6084, 10.3779, 10.4225,  ..., 10.0798, 10.4636, 10.4000],\n",
      "        [10.4304,  9.9260, 10.1746,  ..., 10.5427,  9.4776, 10.4464],\n",
      "        [10.0842, 10.3965, 10.5824,  ...,  9.9751, 10.4545, 10.5857]])\n",
      "--- device cpu, time: 3.840715169906616 ---\n"
     ]
    }
   ],
   "source": [
    "## CPU ONLY\n",
    "start_time = time.time()\n",
    "aa = (((((a ** (1/22)) ** 3) ** 0.1) * 2) ** 3)\n",
    "print(aa)\n",
    "print(\"--- device %s, time: %s ---\" % (a.device, time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[10.5810, 10.2825, 10.5198,  ..., 10.1173, 10.0208, 10.1106],\n",
      "        [ 9.9423, 10.5293, 10.5889,  ...,  9.6341, 10.5749,  9.4456],\n",
      "        [ 9.1943, 10.3175, 10.4476,  ...,  9.0949, 10.4520, 10.2977],\n",
      "        ...,\n",
      "        [ 9.9090, 10.4963, 10.5432,  ..., 10.2093, 10.1330,  9.9714],\n",
      "        [ 9.9068, 10.5601, 10.2474,  ..., 10.5293,  9.0611, 10.1711],\n",
      "        [10.4895,  9.8036, 10.3830,  ..., 10.5360, 10.5013, 10.3467]],\n",
      "       device='cuda:0')\n",
      "--- device cuda:0, time: 0.3745567798614502 ---\n"
     ]
    }
   ],
   "source": [
    "## GPU\n",
    "start_time = time.time()\n",
    "bb = (((((b ** (1/22)) ** 3) ** 0.1) * 2) ** 3)\n",
    "print(bb)\n",
    "print(\"--- device %s, time: %s ---\" % (b.device, time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
